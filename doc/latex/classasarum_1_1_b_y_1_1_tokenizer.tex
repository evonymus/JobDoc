\doxysection{asarum\+::BY\+::Tokenizer Class Reference}
\hypertarget{classasarum_1_1_b_y_1_1_tokenizer}{}\label{classasarum_1_1_b_y_1_1_tokenizer}\index{asarum::BY::Tokenizer@{asarum::BY::Tokenizer}}
\doxysubsubsection*{Static Public Member Functions}
\begin{DoxyCompactItemize}
\item 
static void \mbox{\hyperlink{classasarum_1_1_b_y_1_1_tokenizer_af16f5e2af37a2eec6f585262cdb6b061}{tokenize}} (const std\+::string \&str, const char \texorpdfstring{$\ast$}{*}sep, std\+::vector$<$ std\+::string $>$ \&vec)
\begin{DoxyCompactList}\small\item\em the function splits the provided string using the separator or \textquotesingle{}token\textquotesingle{} and puting the result into the res vector \end{DoxyCompactList}\end{DoxyCompactItemize}


\doxysubsection{Member Function Documentation}
\Hypertarget{classasarum_1_1_b_y_1_1_tokenizer_af16f5e2af37a2eec6f585262cdb6b061}\label{classasarum_1_1_b_y_1_1_tokenizer_af16f5e2af37a2eec6f585262cdb6b061} 
\index{asarum::BY::Tokenizer@{asarum::BY::Tokenizer}!tokenize@{tokenize}}
\index{tokenize@{tokenize}!asarum::BY::Tokenizer@{asarum::BY::Tokenizer}}
\doxysubsubsection{\texorpdfstring{tokenize()}{tokenize()}}
{\footnotesize\ttfamily void asarum\+::\+BY\+::\+Tokenizer\+::tokenize (\begin{DoxyParamCaption}\item[{const std\+::string \&}]{str,  }\item[{const char \texorpdfstring{$\ast$}{*}}]{token,  }\item[{std\+::vector$<$ std\+::string $>$ \&}]{res }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [static]}}



the function splits the provided string using the separator or \textquotesingle{}token\textquotesingle{} and puting the result into the res vector 


\begin{DoxyParams}{Parameters}
{\em str} & the string to split \\
\hline
{\em token} & the separator to use \\
\hline
{\em res} & the vector with splitied strings\\
\hline
\end{DoxyParams}
the function uses \doxylink{classasarum_1_1_b_y_1_1_find_str_t_func}{Find\+Str\+TFunc} \doxysectlink{_find_str_t_func}{declaration of Find\+Str\+TFunc}{0} 

The documentation for this class was generated from the following files\+:\begin{DoxyCompactItemize}
\item 
include/asarum/\+BY/\mbox{\hyperlink{_tokenizer_8h}{Tokenizer.\+h}}\item 
src/Tokenizer.\+cpp\end{DoxyCompactItemize}
